{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2QV47Jfa9vyzxVojDsvCg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacquesBLR/Causal_Inference/blob/main/Impact_d%E2%80%99un_Programme_de_Fid%C3%A9lisation_sur_la_R%C3%A9tention_Client.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contexte et problématique marketing\n",
        "Une enseigne de e-commerce lance un **programme de fidélité** (carte de fidélité, adhésion premium,\n",
        "etc.) pour accroître la rétention de ses clients. Avant le déploiement complet, **un test pilote de type A/B test**\n",
        "a été mené : un échantillon de clients a été **randomisé** en deux groupes – **groupe test** (ayant accès au\n",
        "programme de fidélité) et **groupe témoin** (sans accès) – afin de mesurer l’effet causal du programme\n",
        "sur le comportement client. Le critère principal est le **taux de rétention** des clients (pourcentage de\n",
        "clients toujours actifs/apportant des achats après une période donnée, par ex. 6 mois).\n",
        "Le défi est d’estimer **l’impact causal** du programme de fidélisation sur la rétention. Le test A/B, en tant\n",
        "que **expérience randomisée contrôlée (RCT)**, est le **gold standard** pour estimer un effet causal car la\n",
        "randomisation équilibre les facteurs de confusion entre groupes.  \n",
        "Nous analyserons les résultats de\n",
        "cet A/B test de façon fréquentiste (test statistique classique) puis avec une **approche bayésienne** pour\n",
        "l’interprétation probabiliste. Nous discuterons également des alternatives si la randomisation n’était pas\n",
        "possible (par ex. usage de matching pour comparer adhérents volontaires vs non-adhérents).\n"
      ],
      "metadata": {
        "id": "rnKdS_uCtJQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Données\n",
        "\n",
        "- anciennete : Ancienneté du client (en mois) avant l’étude.\n",
        "- groupe : Indique si le client était dans le groupe “Programme” (traitement) ou “Témoin” (contrôle).\n",
        "- retenu : Indique si le client est resté actif après 6 mois (1 = retenu, 0 = churn)."
      ],
      "metadata": {
        "id": "7X538icItUHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(42) # fixer la graine pour reproductibilité\n",
        "# Paramètres simulés\n",
        "N = 1000\n",
        "# Ancienneté aléatoire entre 1 et 36 mois\n",
        "anciennete = np.random.randint(1, 37, size=N)\n",
        "# Assignation aléatoire au groupe Programme (1) ou Témoin (0)\n",
        "groupe = np.random.binomial(1, 0.5, size=N)\n",
        "# Probabilités de rétention hypothétiques (meilleures pour le groupe fidélité)\n",
        "base_retenu = 0.5 + 0.01 * anciennete # prob. de rétention sans programme\n",
        "effet_programme = 0.10\n",
        "# le programme ajoute ~10 points de rétention\n",
        "prob_retenu = base_retenu + effet_programme * groupe\n",
        "prob_retenu = np.clip(prob_retenu, 0, 0.999) # borne entre 0 et 99.9%\n",
        "# Simulation du statut de rétention\n",
        "retenu = np.random.binomial(1, prob_retenu)\n",
        "# Construire le DataFrame\n",
        "df = pd.DataFrame({\n",
        "'anciennete': anciennete,\n",
        "'groupe': np.where(groupe==1, 'Programme', 'Témoin'),\n",
        "'retenu': retenu\n",
        "})\n",
        "# Calculer le taux de rétention par groupe\n",
        "taux_retenu = df.groupby('groupe')['retenu'].mean()\n",
        "print(\"Taux de rétention Groupe Témoin : {:.1%}\".format(taux_retenu['Témoin']))\n",
        "print(\"Taux de rétention Groupe Programme : {:.1%}\".format(taux_retenu['Programme']))\n",
        "print(\"Différence absolue : {:.1f} points\".format((taux_retenu['Programme']-\n",
        "taux_retenu['Témoin'])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ_5mZCjuYaK",
        "outputId": "484e6ea4-28e3-42d2-da31-b6c530f2625b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taux de rétention Groupe Témoin : 67.8%\n",
            "Taux de rétention Groupe Programme : 78.4%\n",
            "Différence absolue : 10.6 points\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, ~67.8% des clients témoins sont retenus après 6 mois, contre ~78.4% des clients avec la carte de\n",
        "fidélité, soit un **gain d’environ +10.6 points de rétention grâce au programme.**"
      ],
      "metadata": {
        "id": "li_NtwwpvKiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyse statistique (fréquentiste) :  \n",
        "On teste $H_0$ : “le programme n’a aucun effet sur la\n",
        "rétention” (différence = 0) contre $H_1$ : “le programme améliore la rétention”.  \n",
        "On peut appliquer un\n",
        "test de proportion ou un chi² d’indépendance entre groupe et retenu.  \n",
        "Compte tenu des effectifs, on peut utiliser une approximation normale (test Z)."
      ],
      "metadata": {
        "id": "PwVy9ZFdur1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "# Effectifs et conversions par groupe\n",
        "conv_programme = df[df['groupe']=='Programme']['retenu'].sum()\n",
        "n_programme = (df['groupe']=='Programme').sum()\n",
        "conv_témoin = df[df['groupe']=='Témoin']['retenu'].sum()\n",
        "n_témoin = (df['groupe']=='Témoin').sum()\n",
        "# Test de différence de proportions (approx. z)\n",
        "count = np.array([conv_programme, conv_témoin])\n",
        "nobs = np.array([n_programme, n_témoin])\n",
        "stat, p_value = sm.stats.proportions_ztest(count, nobs, alternative='larger')\n",
        "print(\"Statistique Z = {:.2f}, p-value = {:.4f}\".format(stat, p_value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTG61Vs9vSRr",
        "outputId": "368a1f94-8bd8-48f6-d9ab-acb049a6e8a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistique Z = 3.77, p-value = 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cela indique une différence hautement significative (p < 0.001). **On rejette $H_0$** et on conclut que le\n",
        "programme de fidélité augmente significativement la rétention.  \n",
        "Environ +10 points de pourcentage de rétention, c’est un effet substantiel (à confirmer sur la durée et la rentabilité)."
      ],
      "metadata": {
        "id": "LjceA0CXvYy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vérification par régression** : Même si la randomisation garantit en principe l’équilibre des caractéristiques,\n",
        "on peut peaufiner l’estimation via une **régression logistique de *retenu* sur *groupe* en contrôlant\n",
        "l’*anciennete*** .  \n",
        "Cela permet d’estimer l’odd ratio de rétention et de tester l’effet en tenant compte\n",
        "d’une éventuelle légère différence résiduelle de profil."
      ],
      "metadata": {
        "id": "kUBJKhIQvenK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Régression logistique: retenu ~ groupe + anciennete\n",
        "model = smf.logit(formula='retenu ~ groupe + anciennete',\n",
        "data=df.replace({'groupe':{'Témoin':0,'Programme':1}}))\n",
        "result = model.fit(disp=0)\n",
        "print(result.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaP4yg70vhZj",
        "outputId": "0492b3ce-3e7b-4ca1-ceed-26840bfe07ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercept   -0.268928\n",
            "groupe       0.617461\n",
            "tenure       0.055803\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2-3790170026.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  data=df.replace({'groupe':{'Témoin':0,'Programme':1}}))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, **le coefficient de *groupe* (0.62) positif et significatif confirme que l’appartenance au programme\n",
        "augmente la probabilité de rétention** (odd ratio ~ 1.86, soit les chances de rétention multipliées par ~ 1.86) même en contrôlant l’ancienneté.  \n",
        "L’effet estimé en probabilité (~+11 points pour un client moyen)\n",
        "concorde avec le calcul brut. Ceci rassure que le résultat n’est pas dû à un déséquilibre initial des\n",
        "groupes."
      ],
      "metadata": {
        "id": "Zp-zjRxIxnsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approche bayésienne : interprétation plus intuitive pour le décideur\n",
        "Quelle est la probabilité que le programme soit réellement bénéfique ? Plutôt que de simplement dire “p <\n",
        "0.001”, on peut estimer la distribution a posteriori de la différence de taux de rétention entre groupes,\n",
        "via une approche bayésienne."
      ],
      "metadata": {
        "id": "QGVgPXx3xqFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supposons une loi Beta–Binomiale : on assigne a priori à chaque taux de rétention (témoin et\n",
        "programme) une loi Beta(1,1) non-informative (uniforme sur [0,1]). Après observation des données, la\n",
        "loi a posteriori du taux de rétention témoin sera $Beta(\\alpha_{T}, \\beta_{T})$ avec $\\alpha_{T} = 1 +\n",
        "\\text{(nb retenus témoins)}$ et $\\beta_{T} = 1 + \\text{(nb non-retenus témoins)}$. De même pour le\n",
        "groupe programme ($\\alpha_{P}, \\beta_{P}$). On peut alors estimer la distribution a posteriori de la\n",
        "différence $d = p_{P} - p_{T}$ par simulation de Monte Carlo."
      ],
      "metadata": {
        "id": "cJ1nMZNcyh9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy.random as npr\n",
        "# Paramètres postérieurs Beta\n",
        "alpha_T = 1 + conv_témoin\n",
        "beta_T = 1 + (n_témoin - conv_témoin)\n",
        "alpha_P = 1 + conv_programme\n",
        "beta_P = 1 + (n_programme - conv_programme)\n",
        "# Tirages Monte Carlo\n",
        "m = 100000\n",
        "p_temoins = npr.beta(alpha_T, beta_T, size=m)\n",
        "p_program = npr.beta(alpha_P, beta_P, size=m)\n",
        "diff = p_program - p_temoins\n",
        "# Estimation de la probabilité que le programme soit meilleur et intervalle de crédibilité\n",
        "prob = (diff > 0).mean()\n",
        "inf, sup = np.percentile(diff, [2.5, 97.5])\n",
        "print(\"P(diff > 0) = {:.3f}\".format(prob))\n",
        "print(\"IC crédible 95%: [{:.3f}, {:.3f}]\".format(inf, sup))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZQ0oNocylYz",
        "outputId": "c6059778-e65c-4b79-c65f-802f43514dd8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(diff > 0) = 1.000\n",
            "IC crédible 95%: [0.051, 0.160]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut interpréter : « La probabilité a posteriori que le programme de fidélité augmente réellement la\n",
        "rétention est ~99.9% (quasi-certitude). De plus, on estime avec 95% de crédibilité que l’augmentation réelle du\n",
        "taux de rétention se situe entre +5 points et +16 points. » Cette formulation, issue de l’approche\n",
        "bayésienne, est souvent plus parlante pour un marketeur qu’une p-value . On voit que l’intervalle\n",
        "crédible exclut 0 et est plutôt large, reflétant l’incertitude résiduelle sur la magnitude exacte de l’effet."
      ],
      "metadata": {
        "id": "TsEAe_LNzFiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion : hypothèses, limites, interprétation"
      ],
      "metadata": {
        "id": "gE-B5SLyzpeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le cas de la fidélisation illustre une expérimentation aléatoire réussie. Les hypothèses pour valider les\n",
        "conclusions sont :  \n",
        "(1) la randomisation a bien été effectuée (pas de biais de sélection),  \n",
        "(2) il n’y a pas eu\n",
        "de contamination entre groupes (par ex, un client témoin n’a pu bénéficier indirectement du\n",
        "programme),  \n",
        "(3) la période de mesure est suffisante pour capturer l’effet, et  \n",
        "(4) les deux groupes ont été\n",
        "suivis dans des conditions identiques en dehors du traitement.  \n",
        "\n",
        "**Sous ces conditions, on peut interpréter\n",
        "la différence observée comme causale** : le programme de fidélité cause une augmentation du taux de\n",
        "rétention d’environ 10 points dans cet échantillon."
      ],
      "metadata": {
        "id": "P2WdKAwvzrQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limites :**  \n",
        "Un test A/B isolé ne dit rien sur la pérennité de l’effet (quid après 12 mois ?) ni sur la rentabilité\n",
        "(le programme a un coût).  \n",
        "Il indique un effet moyen sur la population testée ; il est possible que l’effet\n",
        "varie selon le profil de clients (il serait intéressant de segmenter par ancienneté, type de client…).  \n",
        "Par ailleurs, la taille d’échantillon doit être suffisante pour détecter l’effet visé (on suppose que le plan\n",
        "d’expérience a pris cela en compte a priori).  \n",
        "Enfin, on a supposé ici un taux d’acceptation de 100% du\n",
        "programme par les clients du groupe test.  \n",
        "En pratique, si l’adhésion au programme était optionnelle,\n",
        "l’effet mesuré serait un mélange d’un effet d’adoption et d’un effet du programme lui-même – cela\n",
        "nécessite une analyse d’intention de traiter ou des méthodes d’ajustement (voir as sur le matching,\n",
        "qui pourrait aussi s’appliquer ici pour comparer adhérents vs non-adhérents a posteriori si la\n",
        "randomisation n’avait pas été possible)."
      ],
      "metadata": {
        "id": "9CiL5bFw0K5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En résumé, ce cas montre la puissance d’un **test contrôlé randomisé** : **c’est la méthode la plus solide\n",
        "pour établir une causalité en marketing** .  \n",
        "Toutefois, on souligne qu’il n’est pas toujours possible de\n",
        "réaliser un tel test (problèmes éthiques, logistiques ou coûts) . Dans ces situations, on se tourne vers\n",
        "des méthodes quasi-expérimentales."
      ],
      "metadata": {
        "id": "USAd0Mv21cvp"
      }
    }
  ]
}